if (!require(data.table)) { install.packages('data.table'); require(data.table) }
if (!require(ggplot2)) { install.packages('ggplot2'); require(ggplot2) }
if (!require(reshape2)) { install.packages('reshape2'); require(reshape2) }
if (!require(devtools)) { install.packages('devtools'); require(devtools) }
if (!require(ggmap)) { install.packages('ggmap'); require(ggmap) }
if (!require(glmnet)) { install.packages('glmnet'); require(glmnet) }
if (!require(fields)) { install.packages('fields'); require(fields) }
if (!require(dplyr)) { install.packages('dplyr'); require(dplyr) }
if (!require(lubridate)) { install.packages('lubridate'); require(lubridate) }
MGH_LONGITUDE = -122.307987
MGH_LATITUDE = 47.655038
PATH_DATA_ALL = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response.csv", sep = "")
PATH_DATA_MGH = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH.csv", sep = "")
PATH_DATA_MGH_TINY = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH_tiny.csv", sep = "")
if(file.exists(PATH_DATA_MGH)){ # switch variable to PATH_DATA_MGH_TINY if there are issues with scale of data
data <- fread(PATH_DATA_MGH, header=T, sep=",")
} else {
data_all = fread(PATH_DATA_ALL, header=T, sep=",")
data_all <- data_all %>% mutate(dist_mgh = sqrt((MGH_LATITUDE-Latitude)^2 + (MGH_LONGITUDE-Longitude)^2)) # Finding crimes closest to MGH
data_mgh <- filter(data_all, dist_mgh<0.01) #22,110 rows
data_mgh_tiny <- filter(data_mgh, dist_mgh<0.007) #5,100 rows
}
#adding columns to the data
data[,at_scene_time_ts := as.POSIXct(strptime(`At Scene Time`, "%m/%d/%Y %I:%M:%S %p"))] #converting time from String to date and time representation (POSIXct)
data[,at_scene_time_hr := hour(ymd_hms(as.character(at_scene_time_ts)))]
data[,at_scene_time_date := as.Date(at_scene_time_ts)]
data[,at_scene_time_week := floor(as.numeric(at_scene_time_date - min(at_scene_time_date, na.rm=T)) / 7) + 1]
data[,event_clearance_ts := as.POSIXct(strptime(`Event Clearance Date`, "%m/%d/%Y %I:%M:%S %p"))]
data[,event_clearance_date := as.Date(event_clearance_ts)]
data[,event_clearance_hr := hour(ymd_hms(as.character(event_clearance_ts)))]
data[,time_until_event_clear := as.numeric(event_clearance_ts - at_scene_time_ts)]
data[,`Initial Type Group` := factor(`Initial Type Group`)]
data[,`Event Clearance Group` := factor(`Event Clearance Group`)]
data[,`Zone/Beat` := factor(`Zone/Beat`)]
data[,LatitudeBin := round(Latitude, 3)]
data[,LongitudeBin := round(Longitude, 3)]
data[,crime_type := ifelse(`Event Clearance Group` %in% crimes.violent, "Violent", ifelse(`Event Clearance Group` %in% crimes.serious, "Serious", "Minor"))]
MGH_LONGITUDE = -122.307987
MGH_LATITUDE = 47.655038
PATH_DATA_ALL = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response.csv", sep = "")
PATH_DATA_MGH = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH.csv", sep = "")
PATH_DATA_MGH_TINY = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH_tiny.csv", sep = "")
if(file.exists(PATH_DATA_MGH)){ # switch variable to PATH_DATA_MGH_TINY if there are issues with scale of data
data <- fread(PATH_DATA_MGH, header=T, sep=",")
} else {
data_all = fread(PATH_DATA_ALL, header=T, sep=",")
data_all <- data_all %>% mutate(dist_mgh = sqrt((MGH_LATITUDE-Latitude)^2 + (MGH_LONGITUDE-Longitude)^2)) # Finding crimes closest to MGH
data_mgh <- filter(data_all, dist_mgh<0.01) #22,110 rows
data_mgh_tiny <- filter(data_mgh, dist_mgh<0.007) #5,100 rows
}
#adding columns to the data
data[,at_scene_time_ts := as.POSIXct(strptime(`At Scene Time`, "%m/%d/%Y %I:%M:%S %p"))] #converting time from String to date and time representation (POSIXct)
data[,at_scene_time_hr := hour(ymd_hms(as.character(at_scene_time_ts)))]
data[,at_scene_time_date := as.Date(at_scene_time_ts)]
data[,at_scene_time_week := floor(as.numeric(at_scene_time_date - min(at_scene_time_date, na.rm=T)) / 7) + 1]
data[,event_clearance_ts := as.POSIXct(strptime(`Event Clearance Date`, "%m/%d/%Y %I:%M:%S %p"))]
data[,event_clearance_date := as.Date(event_clearance_ts)]
data[,event_clearance_hr := hour(ymd_hms(as.character(event_clearance_ts)))]
data[,time_until_event_clear := as.numeric(event_clearance_ts - at_scene_time_ts)]
data[,`Initial Type Group` := factor(`Initial Type Group`)]
data[,`Event Clearance Group` := factor(`Event Clearance Group`)]
data[,`Zone/Beat` := factor(`Zone/Beat`)]
data[,LatitudeBin := round(Latitude, 3)]
data[,LongitudeBin := round(Longitude, 3)]
data[,crime_type := ifelse(`Event Clearance Group` %in% crimes.violent, "Violent", ifelse(`Event Clearance Group` %in% crimes.serious, "Serious", "Minor"))]
MGH_LONGITUDE = -122.307987
MGH_LATITUDE = 47.655038
PATH_DATA_ALL = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response.csv", sep = "")
PATH_DATA_MGH = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH.csv", sep = "")
PATH_DATA_MGH_TINY = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH_tiny.csv", sep = "")
if(file.exists(PATH_DATA_MGH)){ # switch variable to PATH_DATA_MGH_TINY if there are issues with scale of data
data <- fread(PATH_DATA_MGH, header=T, sep=",")
} else {
data_all = fread(PATH_DATA_ALL, header=T, sep=",")
data_all <- data_all %>% mutate(dist_mgh = sqrt((MGH_LATITUDE-Latitude)^2 + (MGH_LONGITUDE-Longitude)^2)) # Finding crimes closest to MGH
data_mgh <- filter(data_all, dist_mgh<0.01) #22,110 rows
data_mgh_tiny <- filter(data_mgh, dist_mgh<0.007) #5,100 rows
}
#adding columns to the data
data[,at_scene_time_ts := as.POSIXct(strptime(`At Scene Time`, "%m/%d/%Y %I:%M:%S %p"))] #converting time from String to date and time representation (POSIXct)
data[,at_scene_time_hr := hour(ymd_hms(as.character(at_scene_time_ts)))]
data[,at_scene_time_date := as.Date(at_scene_time_ts)]
data[,at_scene_time_week := floor(as.numeric(at_scene_time_date - min(at_scene_time_date, na.rm=T)) / 7) + 1]
data[,event_clearance_ts := as.POSIXct(strptime(`Event Clearance Date`, "%m/%d/%Y %I:%M:%S %p"))]
data[,event_clearance_date := as.Date(event_clearance_ts)]
data[,event_clearance_hr := hour(ymd_hms(as.character(event_clearance_ts)))]
data[,time_until_event_clear := as.numeric(event_clearance_ts - at_scene_time_ts)]
data[,`Initial Type Group` := factor(`Initial Type Group`)]
data[,`Event Clearance Group` := factor(`Event Clearance Group`)]
data[,`Zone/Beat` := factor(`Zone/Beat`)]
data[,LatitudeBin := round(Latitude, 3)]
data[,LongitudeBin := round(Longitude, 3)]
data[,crime_type := ifelse(`Event Clearance Group` %in% crimes.violent, "Violent", if else(`Event Clearance Group` %in% crimes.serious, "Serious", "Minor"))]
if (!require(data.table)) { install.packages('data.table'); require(data.table) }
if (!require(ggplot2)) { install.packages('ggplot2'); require(ggplot2) }
if (!require(reshape2)) { install.packages('reshape2'); require(reshape2) }
if (!require(devtools)) { install.packages('devtools'); require(devtools) }
if (!require(ggmap)) { install.packages('ggmap'); require(ggmap) }
if (!require(glmnet)) { install.packages('glmnet'); require(glmnet) }
if (!require(fields)) { install.packages('fields'); require(fields) }
if (!require(dplyr)) { install.packages('dplyr'); require(dplyr) }
if (!require(lubridate)) { install.packages('lubridate'); require(lubridate) }
MGH_LONGITUDE = -122.307987
MGH_LATITUDE = 47.655038
PATH_DATA_ALL = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response.csv", sep = "")
PATH_DATA_MGH = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH.csv", sep = "")
PATH_DATA_MGH_TINY = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH_tiny.csv", sep = "")
if(file.exists(PATH_DATA_MGH)){ # switch variable to PATH_DATA_MGH_TINY if there are issues with scale of data
data <- fread(PATH_DATA_MGH, header=T, sep=",")
} else {
data_all = fread(PATH_DATA_ALL, header=T, sep=",")
data_all <- data_all %>% mutate(dist_mgh = sqrt((MGH_LATITUDE-Latitude)^2 + (MGH_LONGITUDE-Longitude)^2)) # Finding crimes closest to MGH
data_mgh <- filter(data_all, dist_mgh<0.01) #22,110 rows
data_mgh_tiny <- filter(data_mgh, dist_mgh<0.007) #5,100 rows
}
#adding columns to the data
data[,at_scene_time_ts := as.POSIXct(strptime(`At Scene Time`, "%m/%d/%Y %I:%M:%S %p"))] #converting time from String to date and time representation (POSIXct)
data[,at_scene_time_hr := hour(ymd_hms(as.character(at_scene_time_ts)))]
data[,at_scene_time_date := as.Date(at_scene_time_ts)]
data[,at_scene_time_week := floor(as.numeric(at_scene_time_date - min(at_scene_time_date, na.rm=T)) / 7) + 1]
data[,event_clearance_ts := as.POSIXct(strptime(`Event Clearance Date`, "%m/%d/%Y %I:%M:%S %p"))]
data[,event_clearance_date := as.Date(event_clearance_ts)]
data[,event_clearance_hr := hour(ymd_hms(as.character(event_clearance_ts)))]
data[,time_until_event_clear := as.numeric(event_clearance_ts - at_scene_time_ts)]
data[,`Initial Type Group` := factor(`Initial Type Group`)]
data[,`Event Clearance Group` := factor(`Event Clearance Group`)]
data[,`Zone/Beat` := factor(`Zone/Beat`)]
data[,LatitudeBin := round(Latitude, 3)]
data[,LongitudeBin := round(Longitude, 3)]
data[,crime_type := ifelse(`Event Clearance Group` %in% crimes.violent, "Violent", ifelse(`Event Clearance Group` %in% crimes.serious, "Serious", "Minor"))]
MGH_LONGITUDE = -122.307987
MGH_LATITUDE = 47.655038
PATH_DATA_ALL = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response.csv", sep = "")
PATH_DATA_MGH = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH.csv", sep = "")
PATH_DATA_MGH_TINY = paste(getwd(), "/data/Seattle_Police_Department_911_Incident_Response_Near_MGH_tiny.csv", sep = "")
if(file.exists(PATH_DATA_MGH)){ # switch variable to PATH_DATA_MGH_TINY if there are issues with scale of data
data <- fread(PATH_DATA_MGH, header=T, sep=",")
} else {
data_all = fread(PATH_DATA_ALL, header=T, sep=",")
data_all <- data_all %>% mutate(dist_mgh = sqrt((MGH_LATITUDE-Latitude)^2 + (MGH_LONGITUDE-Longitude)^2)) # Finding crimes closest to MGH
data_mgh <- filter(data_all, dist_mgh<0.01) #22,110 rows
data_mgh_tiny <- filter(data_mgh, dist_mgh<0.007) #5,100 rows
}
#adding columns to the data
data[,at_scene_time_ts := as.POSIXct(strptime(`At Scene Time`, "%m/%d/%Y %I:%M:%S %p"))] #converting time from String to date and time representation (POSIXct)
data[,at_scene_time_hr := hour(ymd_hms(as.character(at_scene_time_ts)))]
data[,at_scene_time_date := as.Date(at_scene_time_ts)]
data[,at_scene_time_week := floor(as.numeric(at_scene_time_date - min(at_scene_time_date, na.rm=T)) / 7) + 1]
data[,event_clearance_ts := as.POSIXct(strptime(`Event Clearance Date`, "%m/%d/%Y %I:%M:%S %p"))]
data[,event_clearance_date := as.Date(event_clearance_ts)]
data[,event_clearance_hr := hour(ymd_hms(as.character(event_clearance_ts)))]
data[,time_until_event_clear := as.numeric(event_clearance_ts - at_scene_time_ts)]
data[,`Initial Type Group` := factor(`Initial Type Group`)]
data[,`Event Clearance Group` := factor(`Event Clearance Group`)]
data[,`Zone/Beat` := factor(`Zone/Beat`)]
data[,LatitudeBin := round(Latitude, 3)]
data[,LongitudeBin := round(Longitude, 3)]
data[,crime_type := if else(`Event Clearance Group` %in% crimes.violent, "Violent", if else(`Event Clearance Group` %in% crimes.serious, "Serious", "Minor"))]
View(data)
total_reports = nrow(data)
total_reports
# write code below!
blank_values <- data %>% filter(is.na(at_scene_time_ts) == TRUE)
blank_values
blank_values_count <- nrow(blank_values)
proportion <- blank_values_count / total_reports
sanityCheck = data.frame(data[,table(weekdays(event_clearance_date))]); # frequency of crimes by day of week
View(sanityCheck)
sanityCheck$Var1 = factor(sanityCheck$Var1, levels = rev(c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))
ggplot(sanityCheck,
aes(x = Var1, y = Freq, fill = as.numeric(Var1) %% 2)) +
geom_bar(stat = 'identity') +
coord_flip() +
theme_bw() +
xlab ("Day of Week") + ylab("Count") +
guides(fill=F)
sanityCheck = data.frame(data[,table(weekdays(event_clearance_date))]); # frequency of crimes by day of week
View(sanityCheck)
sanityCheck$Var1 = factor(sanityCheck$Var1, levels = rev(c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))
ggplot(sanityCheck,
aes(x = Var1, y = Freq, fill = as.numeric(Var1) %% 2)) +
geom_bar(stat = 'identity') +
coord_flip() +
theme_bw() +
xlab ("Day of Week") + ylab("Count") +
guides(fill=F)
qplot(x= data$at_scene_time_ts)
qplot(x= data$at_scene_time_hr)
#Uses a frequency table to build a bar chart that is ordered by the counts
ggplot.freqtable.1d = function(x) {
freq = data.frame(x); colnames(freq)[1] = "label"
freq.filtered = droplevels(subset(freq, label != "" & !is.na(label)))
freq.filtered$label = factor(freq.filtered$label,
levels = as.character(freq.filtered[order(freq.filtered$Freq, decreasing = F),]$label),
ordered = F)
ggplot(freq.filtered,
aes(x = label, y = Freq, fill = label)) +
geom_bar(stat = 'identity') +
coord_flip() +
theme_grey()
}
#Ploting frequency of each type of report
ggplot.freqtable.1d(data[,table(`Event Clearance Group`)]) +
xlab("Contact Type") + ylab("Count") +
theme_bw() +
guides(fill=F)
